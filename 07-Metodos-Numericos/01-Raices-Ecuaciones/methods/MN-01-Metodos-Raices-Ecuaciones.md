<!--
::METADATA::
type: method
status: active
-->


> üè† **Navegaci√≥n:** [‚Üê Volver al √çndice Principal](../../../glossary.md)

---

# M√©todos: Ra√≠ces de Ecuaciones

> **Referencia r√°pida:** Esta gu√≠a presenta 10 [m√©todos num√©ricos](../../../glossary.md#metodos-numericos) para encontrar [ra√≠ces de ecuaciones](../../../glossary.md#raices-de-ecuaciones) $f(x) = 0$ con algoritmos detallados y an√°lisis de [convergencia](../../../glossary.md#convergencia).

---

## √çndice de M√©todos

| # | M√©todo | [Convergencia](#m√©todo-1-bisecci√≥n) | Lineal | ‚≠ê |
| 2 | [Falsa Posici√≥n](#m√©todo-3-newton-raphson) | Cuadr√°tica | ‚≠ê‚≠ê |
| 4 | [Secante](#m√©todo-5-punto-fijo) | Lineal | ‚≠ê‚≠ê |
| 6 | [Newton Modificado](#m√©todo-7-m√ºller) | Superlineal (1.84) | ‚≠ê‚≠ê‚≠ê |
| 8 | [Steffensen](#m√©todo-9-brent) | Superlineal | ‚≠ê‚≠ê‚≠ê‚≠ê |
| 10 | [Newton Multivariable](#m√©todo-10-newton-para-sistemas) | Cuadr√°tica | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## Conceptos Fundamentales

### Tipos de Convergencia

| Tipo | Definici√≥n | Ejemplo |
|------|------------|---------|
| **Lineal** | $\vert e_{n+1}\vert \approx c\vert e_n\vert$ con $0 < c < 1$ | Bisecci√≥n |
| **Cuadr√°tica** | $\vert e_{n+1}\vert \approx c\vert e_n\vert^2$ | Newton-Raphson |
| **Orden $p$** | $\vert e_{n+1}\vert \approx c\vert e_n\vert^p$ | Secante ($p \approx 1.618$) |

### Criterios de Parada

1. **Tolerancia absoluta:** $|x_{n+1} - x_n| < \varepsilon$
2. **Tolerancia relativa:** $\frac{|x_{n+1} - x_n|}{|x_{n+1}|} < \varepsilon$
3. **Residuo:** $|f(x_n)| < \varepsilon$
4. **M√°ximo iteraciones:** $n > N_{\max}$

---

## M√©todo 1: Bisecci√≥n

### Cu√°ndo Usar

- Se conoce un intervalo $[a,b]$ con cambio de signo
- Se necesita **garant√≠a de convergencia**
- Robustez m√°s importante que velocidad

### F√≥rmula

$$c = \frac{a + b}{2}$$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Verificar** | $f(a) \cdot f(b) < 0$ |
| 2 | **Calcular** | $c = \frac{a+b}{2}$ |
| 3 | **Evaluar** | $f(c)$ |
| 4 | **Actualizar** | Si $f(a)f(c) < 0$: $b = c$; sino: $a = c$ |
| 5 | **Verificar** | Si $\vert b-a\vert < 2\varepsilon$: terminar |
| 6 | **Repetir** | Desde paso 2 |

### Pseudoc√≥digo

```python
def biseccion(f, a, b, tol=1e-6, max_iter=100):
    if f(a) * f(b) >= 0:
        raise ValueError("f(a) y f(b) deben tener signos opuestos")
    
    for i in range(max_iter):
        c = (a + b) / 2
        if abs(b - a) < 2 * tol:
            return c, i
        if f(a) * f(c) < 0:
            b = c
        else:
            a = c
    
    return c, max_iter
```

### Ejemplo Detallado

**Problema:** Encontrar la ra√≠z de $f(x) = x^3 - x - 2$ en $[1, 2]$ con $\varepsilon = 0.01$

---

**Verificaci√≥n inicial:**
$f(1) = 1 - 1 - 2 = -2 < 0$
$f(2) = 8 - 2 - 2 = 4 > 0$
$f(1) \cdot f(2) < 0$ ‚úì

---

**Iteraciones:**

| $n$ | $a$ | $b$ | $c = \frac{a+b}{2}$ | $f(c)$ | Acci√≥n |
|:---:|:---:|:---:|:-------------------:|:------:|--------|
| 1 | 1.000 | 2.000 | 1.500 | -0.125 | $a = 1.5$ |
| 2 | 1.500 | 2.000 | 1.750 | +1.609 | $b = 1.75$ |
| 3 | 1.500 | 1.750 | 1.625 | +0.666 | $b = 1.625$ |
| 4 | 1.500 | 1.625 | 1.5625 | +0.252 | $b = 1.5625$ |
| 5 | 1.500 | 1.5625 | 1.5313 | +0.059 | $b = 1.5313$ |
| 6 | 1.500 | 1.5313 | 1.5156 | -0.034 | $a = 1.5156$ |
| 7 | 1.5156 | 1.5313 | 1.5234 | +0.012 | $b = 1.5234$ |

$|b - a| = 0.0078 < 2(0.01) = 0.02$ ‚Üí Terminar

$$\boxed{x^* \approx 1.5195}$$

---

**N√∫mero de iteraciones necesarias:**

$$n \geq \frac{\ln(b-a) - \ln(2\varepsilon)}{\ln 2}$$

Para $[1,2]$ y $\varepsilon = 10^{-6}$: $n \geq \frac{\ln 1 - \ln(2 \times 10^{-6})}{\ln 2} \approx 19$ iteraciones

---

## M√©todo 2: Falsa Posici√≥n (Regula Falsi)

### Cu√°ndo Usar

- Similar a bisecci√≥n pero potencialmente m√°s r√°pido
- Intervalo con cambio de signo conocido
- [Funci√≥n](../../../glossary.md#funcion) relativamente lineal

### F√≥rmula

$$c = b - f(b)\frac{b - a}{f(b) - f(a)} = \frac{af(b) - bf(a)}{f(b) - f(a)}$$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Verificar** | $f(a) \cdot f(b) < 0$ |
| 2 | **Calcular** | $c = \frac{af(b) - bf(a)}{f(b) - f(a)}$ |
| 3 | **Evaluar** | $f(c)$ |
| 4 | **Actualizar** | Si $f(a)f(c) < 0$: $b = c$; sino: $a = c$ |
| 5 | **Verificar** | Si $\vert f(c)\vert < \varepsilon$: terminar |
| 6 | **Repetir** | Desde paso 2 |

### Pseudoc√≥digo

```python
def falsa_posicion(f, a, b, tol=1e-6, max_iter=100):
    fa, fb = f(a), f(b)
    if fa * fb >= 0:
        raise ValueError("f(a) y f(b) deben tener signos opuestos")
    
    for i in range(max_iter):
        c = (a * fb - b * fa) / (fb - fa)
        fc = f(c)
        
        if abs(fc) < tol:
            return c, i
        
        if fa * fc < 0:
            b, fb = c, fc
        else:
            a, fa = c, fc
    
    return c, max_iter
```

### Ejemplo Detallado

**Problema:** Encontrar la ra√≠z de $f(x) = x^3 - x - 2$ en $[1, 2]$

---

**Iteraciones:**

| $n$ | $a$ | $b$ | $c$ | $f(c)$ |
|:---:|:---:|:---:|:---:|:------:|
| 1 | 1.000 | 2.000 | 1.333 | -0.963 |
| 2 | 1.333 | 2.000 | 1.470 | -0.294 |
| 3 | 1.470 | 2.000 | 1.506 | -0.073 |
| 4 | 1.506 | 2.000 | 1.515 | -0.017 |
| 5 | 1.515 | 2.000 | 1.517 | -0.004 |

$$\boxed{x^* \approx 1.5214}$$

---

**Problema:** El extremo $b = 2$ nunca se mueve (convergencia lenta). Soluci√≥n: **Illinois Algorithm** modifica $f(a)$ o $f(b)$ si un extremo permanece fijo.

---

## M√©todo 3: Newton-Raphson

### Cu√°ndo Usar

- Se tiene $f'(x)$ disponible
- Se necesita convergencia r√°pida
- Buen punto inicial disponible

### F√≥rmula

$$x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$$

### Interpretaci√≥n Geom√©trica

La recta [tangente](../../../glossary.md#tangente) a $f$ en $x_n$ corta al eje $x$ en $x_{n+1}$.

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Elegir** | Punto inicial $x_0$ |
| 2 | **Evaluar** | $f(x_n)$ y $f'(x_n)$ |
| 3 | **Verificar** | Si $\vert f'(x_n)\vert \approx 0$: problema |
| 4 | **Calcular** | $x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$ |
| 5 | **Verificar** | Si $\vert x_{n+1} - x_n\vert < \varepsilon$: terminar |
| 6 | **Repetir** | Desde paso 2 |

### Pseudoc√≥digo

```python
def newton_raphson(f, df, x0, tol=1e-10, max_iter=100):
    x = x0
    for i in range(max_iter):
        fx = f(x)
        dfx = df(x)
        
        if abs(dfx) < 1e-14:
            raise ValueError("Derivada muy peque√±a")
        
        x_new = x - fx / dfx
        
        if abs(x_new - x) < tol:
            return x_new, i + 1
        
        x = x_new
    
    return x, max_iter
```

### Ejemplo Detallado

**Problema:** Calcular $\sqrt{2}$ resolviendo $f(x) = x^2 - 2 = 0$

---

$f(x) = x^2 - 2$, $f'(x) = 2x$

F√≥rmula: $x_{n+1} = x_n - \frac{x_n^2 - 2}{2x_n} = \frac{x_n^2 + 2}{2x_n} = \frac{x_n + 2/x_n}{2}$

---

**Iteraciones con** $x_0 = 1$:

| $n$ | $x_n$ | $f(x_n)$ | $f'(x_n)$ | $x_{n+1}$ | Error |
|:---:|:-----:|:--------:|:---------:|:---------:|:-----:|
| 0 | 1.000000 | -1.000 | 2.000 | 1.500000 | 0.500 |
| 1 | 1.500000 | 0.250 | 3.000 | 1.416667 | 0.083 |
| 2 | 1.416667 | 0.00694 | 2.833 | 1.414216 | 0.00245 |
| 3 | 1.414216 | 0.00001 | 2.828 | 1.414214 | 0.000002 |

$$\boxed{\sqrt{2} \approx 1.41421356}$$

---

**Convergencia cuadr√°tica:** El error en cada paso es aproximadamente el cuadrado del error anterior.

$e_1 \approx 0.086$, $e_2 \approx 0.0025 \approx (0.086)^2 \times 0.35$

---

### An√°lisis de Convergencia

$$e_{n+1} \approx \frac{f''(x^*)}{2f'(x^*)} e_n^2$$

**Convergencia garantizada si:**
- $x_0$ suficientemente cerca de $x^*$
- $f'(x^*) \neq 0$
- $f''$ continua cerca de $x^*$

---

## M√©todo 4: Secante

### Cu√°ndo Usar

- No se tiene $f'(x)$ disponible
- Se desea convergencia m√°s r√°pida que bisecci√≥n
- Se tienen dos puntos iniciales

### F√≥rmula

$$x_{n+1} = x_n - f(x_n)\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}$$

### Interpretaci√≥n

Aproxima $f'(x_n)$ con la diferencia finita $\frac{f(x_n) - f(x_{n-1})}{x_n - x_{n-1}}$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Elegir** | Dos puntos $x_0$, $x_1$ |
| 2 | **Evaluar** | $f(x_n)$ y $f(x_{n-1})$ |
| 3 | **Calcular** | $x_{n+1} = x_n - f(x_n)\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}$ |
| 4 | **Verificar** | Si $\vert x_{n+1} - x_n\vert < \varepsilon$: terminar |
| 5 | **Actualizar** | $x_{n-1} = x_n$, $x_n = x_{n+1}$ |
| 6 | **Repetir** | Desde paso 2 |

### Pseudoc√≥digo

```python
def secante(f, x0, x1, tol=1e-10, max_iter=100):
    f0, f1 = f(x0), f(x1)
    
    for i in range(max_iter):
        if abs(f1 - f0) < 1e-14:
            raise ValueError("Divisi√≥n por cero")
        
        x2 = x1 - f1 * (x1 - x0) / (f1 - f0)
        
        if abs(x2 - x1) < tol:
            return x2, i + 1
        
        x0, f0 = x1, f1
        x1, f1 = x2, f(x2)
    
    return x1, max_iter
```

### Ejemplo Detallado

**Problema:** Resolver $f(x) = x^3 - x - 2 = 0$ con $x_0 = 1$, $x_1 = 2$

---

| $n$ | $x_{n-1}$ | $x_n$ | $f(x_{n-1})$ | $f(x_n)$ | $x_{n+1}$ |
|:---:|:---------:|:-----:|:------------:|:--------:|:---------:|
| 2 | 1.000 | 2.000 | -2.000 | 4.000 | 1.333 |
| 3 | 2.000 | 1.333 | 4.000 | -0.963 | 1.511 |
| 4 | 1.333 | 1.511 | -0.963 | -0.057 | 1.520 |
| 5 | 1.511 | 1.520 | -0.057 | -0.008 | 1.521 |
| 6 | 1.520 | 1.521 | -0.008 | 0.0003 | 1.5214 |

$$\boxed{x^* \approx 1.52138}$$

---

**[Orden de convergencia](../../../glossary.md#orden-de-convergencia):** $p = \frac{1 + \sqrt{5}}{2} \approx 1.618$ (n√∫mero √°ureo)

---

## M√©todo 5: Punto Fijo

### Cu√°ndo Usar

- La ecuaci√≥n se puede escribir como $x = g(x)$
- Para entender convergencia de otros m√©todos
- Como t√©cnica general de iteraci√≥n

### F√≥rmula

$$x_{n+1} = g(x_n)$$

### Condici√≥n de Convergencia

Si $|g'(x)| < 1$ en un entorno de la ra√≠z $x^*$, entonces el m√©todo converge para puntos iniciales suficientemente cercanos.

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Reformular** | $f(x) = 0$ como $x = g(x)$ |
| 2 | **Verificar** | $\vert g'(x^*)\vert < 1$ (si es posible) |
| 3 | **Elegir** | Punto inicial $x_0$ |
| 4 | **Calcular** | $x_{n+1} = g(x_n)$ |
| 5 | **Verificar** | Si $\vert x_{n+1} - x_n\vert < \varepsilon$: terminar |
| 6 | **Repetir** | Desde paso 4 |

### Pseudoc√≥digo

```python
def punto_fijo(g, x0, tol=1e-6, max_iter=100):
    x = x0
    for i in range(max_iter):
        x_new = g(x)
        
        if abs(x_new - x) < tol:
            return x_new, i + 1
        
        x = x_new
    
    return x, max_iter
```

### Ejemplo Detallado

**Problema:** Resolver $e^{-x} - x = 0$

---

**Reformulaci√≥n:** $x = e^{-x} = g(x)$

**Verificar convergencia:**
$g'(x) = -e^{-x}$
$|g'(0.5)| = e^{-0.5} \approx 0.607 < 1$ ‚úì

---

**Iteraciones con** $x_0 = 0.5$:

| $n$ | $x_n$ | $g(x_n) = e^{-x_n}$ | $\vert x_{n+1} - x_n\vert$ |
|:---:|:-----:|:-------------------:|:--------------------------:|
| 0 | 0.5000 | 0.6065 | 0.1065 |
| 1 | 0.6065 | 0.5452 | 0.0613 |
| 2 | 0.5452 | 0.5797 | 0.0345 |
| 3 | 0.5797 | 0.5601 | 0.0196 |
| 4 | 0.5601 | 0.5711 | 0.0111 |
| 5 | 0.5711 | 0.5649 | 0.0062 |
| ... | ... | ... | ... |
| 20 | 0.5671 | 0.5671 | < 0.0001 |

$$\boxed{x^* \approx 0.56714}$$

---

### Diferentes Reformulaciones

Para $x^3 - x - 2 = 0$:

1. $x = x^3 - 2$ ‚Üí $g'(x) = 3x^2$ ‚Üí diverge cerca de $x = 1.5$
2. $x = (x + 2)^{1/3}$ ‚Üí $g'(x) = \frac{1}{3}(x+2)^{-2/3}$ ‚Üí converge
3. $x = \frac{2}{x^2 - 1}$ ‚Üí puede converger o diverger

---

## M√©todo 6: Newton Modificado (Ra√≠ces M√∫ltiples)

### Cu√°ndo Usar

- Ra√≠z de multiplicidad $m > 1$
- Newton est√°ndar converge lentamente

### F√≥rmula (Conociendo Multiplicidad)

$$x_{n+1} = x_n - m\frac{f(x_n)}{f'(x_n)}$$

### F√≥rmula (Sin Conocer Multiplicidad)

Usar $u(x) = \frac{f(x)}{f'(x)}$ que tiene ra√≠ces simples:

$$x_{n+1} = x_n - \frac{u(x_n)}{u'(x_n)} = x_n - \frac{f(x_n)f'(x_n)}{[f'(x_n)]^2 - f(x_n)f''(x_n)}$$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Detectar** | Si Newton converge lentamente, sospechar ra√≠z m√∫ltiple |
| 2 | **Estimar** $m$ | $m \approx \frac{f(x_n)}{f(x_n) - f(x_{n+1})}$ en Newton est√°ndar |
| 3 | **Aplicar** | Newton modificado con $m$ o usar $u(x)$ |
| 4 | **Verificar** | Convergencia cuadr√°tica restaurada |

### Ejemplo Detallado

**Problema:** Encontrar la ra√≠z de $f(x) = (x-1)^3 = x^3 - 3x^2 + 3x - 1$

---

**Newton est√°ndar** (convergencia lineal):

$f'(x) = 3(x-1)^2$

| $n$ | $x_n$ | Error |
|:---:|:-----:|:-----:|
| 0 | 2.000 | 1.000 |
| 1 | 1.667 | 0.667 |
| 2 | 1.444 | 0.444 |
| 3 | 1.296 | 0.296 |

Convergencia lenta ‚Üí ra√≠z m√∫ltiple

---

**Newton modificado con** $m = 3$:

$$x_{n+1} = x_n - 3\frac{f(x_n)}{f'(x_n)}$$

| $n$ | $x_n$ | Error |
|:---:|:-----:|:-----:|
| 0 | 2.000 | 1.000 |
| 1 | 1.000 | 0.000 |

$$\boxed{x^* = 1 \text{ (convergencia en 1 iteraci√≥n)}}$$

---

## M√©todo 7: M√ºller

### Cu√°ndo Usar

- Puede encontrar ra√≠ces complejas
- No requiere [derivada](../../../glossary.md#derivada)
- Usa [interpolaci√≥n](../../../glossary.md#interpolacion) parab√≥lica

### F√≥rmula

Dados tres puntos $x_0, x_1, x_2$, ajustar par√°bola y encontrar ra√≠z:

$$x_3 = x_2 - \frac{2c}{b \pm \sqrt{b^2 - 4ac}}$$

donde $a, b, c$ son coeficientes de la par√°bola $p(x) = a(x-x_2)^2 + b(x-x_2) + c$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Elegir** | Tres puntos $x_0, x_1, x_2$ |
| 2 | **Calcular** | $f_0, f_1, f_2$ |
| 3 | **Calcular** | $h_0 = x_1 - x_0$, $h_1 = x_2 - x_1$ |
| 4 | **Calcular** | Diferencias divididas |
| 5 | **Formar** | Coeficientes $a, b, c$ |
| 6 | **Resolver** | Para $x_3$ |
| 7 | **Actualizar** | $(x_0, x_1, x_2) \leftarrow (x_1, x_2, x_3)$ |

### Pseudoc√≥digo

```python
def muller(f, x0, x1, x2, tol=1e-10, max_iter=100):
    for i in range(max_iter):
        f0, f1, f2 = f(x0), f(x1), f(x2)
        
        h1 = x1 - x0
        h2 = x2 - x1
        delta1 = (f1 - f0) / h1
        delta2 = (f2 - f1) / h2
        
        a = (delta2 - delta1) / (h2 + h1)
        b = a * h2 + delta2
        c = f2
        
        discriminante = cmath.sqrt(b**2 - 4*a*c)
        
        if abs(b + discriminante) > abs(b - discriminante):
            denom = b + discriminante
        else:
            denom = b - discriminante
        
        dx = -2 * c / denom
        x3 = x2 + dx
        
        if abs(dx) < tol:
            return x3, i + 1
        
        x0, x1, x2 = x1, x2, x3
    
    return x2, max_iter
```

### Ejemplo

**Problema:** Encontrar ra√≠ces de $f(x) = x^3 - 1$ (incluye complejas)

Con puntos iniciales reales, M√ºller puede encontrar ra√≠ces complejas:

$$x = 1, \quad x = -\frac{1}{2} + \frac{\sqrt{3}}{2}i, \quad x = -\frac{1}{2} - \frac{\sqrt{3}}{2}i$$

---

## M√©todo 8: Steffensen

### Cu√°ndo Usar

- Para acelerar punto fijo a convergencia cuadr√°tica
- Sin calcular [derivada](../../../glossary.md#derivada)

### F√≥rmula (Aceleraci√≥n de Aitken)

$$x_{n+1} = x_n - \frac{(x_n^{(1)} - x_n)^2}{x_n^{(2)} - 2x_n^{(1)} + x_n}$$

donde $x_n^{(1)} = g(x_n)$ y $x_n^{(2)} = g(x_n^{(1)})$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Calcular** | $x^{(1)} = g(x_n)$ |
| 2 | **Calcular** | $x^{(2)} = g(x^{(1)})$ |
| 3 | **Aplicar Aitken** | $x_{n+1} = x_n - \frac{(x^{(1)} - x_n)^2}{x^{(2)} - 2x^{(1)} + x_n}$ |
| 4 | **Verificar** | Convergencia |

### Pseudoc√≥digo

```python
def steffensen(g, x0, tol=1e-10, max_iter=100):
    x = x0
    for i in range(max_iter):
        x1 = g(x)
        x2 = g(x1)
        
        denom = x2 - 2*x1 + x
        if abs(denom) < 1e-14:
            return x1, i + 1
        
        x_new = x - (x1 - x)**2 / denom
        
        if abs(x_new - x) < tol:
            return x_new, i + 1
        
        x = x_new
    
    return x, max_iter
```

### Ejemplo Detallado

**Problema:** Resolver $e^{-x} = x$ con $g(x) = e^{-x}$

---

**Punto fijo est√°ndar:** ~20 iteraciones
**Steffensen:** ~5 iteraciones

| $n$ | $x_n$ | $x^{(1)}$ | $x^{(2)}$ | $x_{n+1}$ |
|:---:|:-----:|:---------:|:---------:|:---------:|
| 0 | 0.500 | 0.6065 | 0.5452 | 0.5663 |
| 1 | 0.5663 | 0.5676 | 0.5669 | 0.5671 |
| 2 | 0.5671 | 0.5671 | 0.5671 | 0.5671 |

$$\boxed{x^* \approx 0.56714}$$

---

## M√©todo 9: Brent

### Cu√°ndo Usar

- M√©todo robusto de prop√≥sito general
- Combina bisecci√≥n, secante y cuadr√°tica inversa
- Implementaci√≥n est√°ndar en bibliotecas

### Idea Principal

1. Mantener intervalo que encierra la ra√≠z (como bisecci√≥n)
2. Usar [interpolaci√≥n](../../../glossary.md#interpolacion) cuando es seguro y efectivo
3. Revertir a bisecci√≥n si el progreso es insuficiente

### Caracter√≠sticas

| Propiedad | Valor |
|-----------|-------|
| Garant√≠a de convergencia | ‚úì |
| [Orden](../../../glossary.md#orden) de convergencia | Variable |
| Robustez | Muy alta |
| Eficiencia | Alta |

---

## M√©todo 10: Newton para Sistemas No Lineales

### Cu√°ndo Usar
- Resolver $\mathbf{F}(\mathbf{x}) = \mathbf{0}$
- Sistema de ecuaciones no lineales

### F√≥rmula
$$\mathbf{x}_{n+1} = \mathbf{x}_n - \mathbf{J}^{-1}(\mathbf{x}_n)\mathbf{F}(\mathbf{x}_n)$$

donde $\mathbf{J}$ es la [matriz](../../../glossary.md#matriz) jacobiana:

$$J_{ij} = \frac{\partial F_i}{\partial x_j}$$

### Algoritmo de Resoluci√≥n

| Paso | Acci√≥n | Detalle |
|:----:|--------|---------|
| 1 | **Evaluar** | $\mathbf{F}(\mathbf{x}_n)$ |
| 2 | **Calcular** | Jacobiano $\mathbf{J}(\mathbf{x}_n)$ |
| 3 | **Resolver** | $\mathbf{J}\Delta\mathbf{x} = -\mathbf{F}$ |
| 4 | **Actualizar** | $\mathbf{x}_{n+1} = \mathbf{x}_n + \Delta\mathbf{x}$ |
| 5 | **Verificar** | $\|\Delta\mathbf{x}\| < \varepsilon$ |

### Ejemplo Detallado

**Problema:** Resolver el sistema
$$\begin{cases} x^2 + y^2 = 4 \\ xy = 1 \end{cases}$$

---

$F_1(x,y) = x^2 + y^2 - 4$
$F_2(x,y) = xy - 1$

**Jacobiano:**
$$\mathbf{J} = \begin{pmatrix} 2x & 2y \\ y & x \end{pmatrix}$$

---

**Iteraci√≥n con** $\mathbf{x}_0 = (1.5, 1.5)$:

$\mathbf{F}(\mathbf{x}_0) = (0.5, 1.25)$

$\mathbf{J}(\mathbf{x}_0) = \begin{pmatrix} 3 & 3 \\ 1.5 & 1.5 \end{pmatrix}$

Resolver: $\begin{pmatrix} 3 & 3 \\ 1.5 & 1.5 \end{pmatrix}\begin{pmatrix} \Delta x \\ \Delta y \end{pmatrix} = \begin{pmatrix} -0.5 \\ -1.25 \end{pmatrix}$

La [matriz](../../../glossary.md#matriz) es singular en este punto, necesitamos mejor punto inicial.

---

**Con** $\mathbf{x}_0 = (1.8, 0.6)$:

Despu√©s de 4-5 iteraciones:

$$\boxed{(x^*, y^*) \approx (1.9319, 0.5176)}$$

---

## Diagrama de Decisi√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       ENCONTRAR RA√çZ DE f(x) = 0            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ ¬øConoces [a,b] con    ‚îÇ
        ‚îÇ f(a)¬∑f(b) < 0?        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
          S√ç‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄNO
          ‚îÇ                   ‚îÇ
          ‚ñº                   ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ¬øNecesitas ‚îÇ      ‚îÇ¬øTienes    ‚îÇ
    ‚îÇgarant√≠a?  ‚îÇ      ‚îÇf'(x)?     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                   ‚îÇ
     S√ç‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄNO        S√ç‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄNO
     ‚îÇ        ‚îÇ         ‚îÇ        ‚îÇ
     ‚ñº        ‚ñº         ‚ñº        ‚ñº
  Bisecci√≥n  Brent   Newton   Secante
             Falsa            Punto
             Posici√≥n         Fijo
```

---

## Tabla de Comparaci√≥n

| M√©todo | Convergencia | Evaluaciones/iter | Robusto | Derivada |
|--------|:------------:|:-----------------:|:-------:|:--------:|
| Bisecci√≥n | Lineal | 1 | ‚úì‚úì‚úì | No |
| Falsa Posici√≥n | Superlineal | 1 | ‚úì‚úì | No |
| Newton | Cuadr√°tica | 2 | ‚úì | S√≠ |
| Secante | 1.618 | 1 | ‚úì | No |
| Punto Fijo | Lineal | 1 | ‚úì | No |
| Steffensen | Cuadr√°tica | 2 | ‚úì | No |
| M√ºller | 1.84 | 1 | ‚úì | No |
| Brent | Superlineal | 1-2 | ‚úì‚úì‚úì | No |

---

## Errores Comunes a Evitar

| Error | Consecuencia | Prevenci√≥n |
|-------|--------------|------------|
| Divisi√≥n por cero en Newton | Falla del m√©todo | Verificar $f'(x_n) \neq 0$ |
| Mal punto inicial | No convergencia | Graficar primero |
| Intervalo sin cambio de signo | Bisecci√≥n falla | Verificar $f(a)f(b) < 0$ |
| $\vert g'\vert \geq 1$ en punto fijo | [Divergencia](../../../glossary.md#maquina) |

---

## Problemas de Pr√°ctica Sugeridos

1. **Bisecci√≥n:** $\cos x - x = 0$ en $[0, 1]$

2. **Newton:** $x^3 - 2x - 5 = 0$ con $x_0 = 2$

3. **Secante:** $e^x + x = 0$ con $x_0 = 0$, $x_1 = -1$

4. **Punto fijo:** Diferentes reformulaciones de $x^3 = 2x + 5$

5. **Sistema:** $x^2 - y = 0$, $x + y^2 = 2$

6. **Ra√≠z m√∫ltiple:** $(x - 2)^2(x + 1) = 0$

---

*Documento actualizado con formato expandido para estudio detallado.*
