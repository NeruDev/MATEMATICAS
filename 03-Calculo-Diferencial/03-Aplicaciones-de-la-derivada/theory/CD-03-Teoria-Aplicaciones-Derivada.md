<!--
HUMANO:
TeorÃ­a de aplicaciones de la [derivada](../../..](../../../glossary.md)#derivada).

IA:
Conceptos de optimizaciÃ³n, anÃ¡lisis de funciones.

---
content_type: theory
expected_output:
  default: markdown
audience: self-study
---
-->


> ğŸ  **NavegaciÃ³n:** [â† Volver al Ãndice Principal](../../../WIKI_INDEX.md) | [ğŸ“š Glosario](../../../glossary.md)

---

# TeorÃ­a de Aplicaciones de la Derivada

## 3.1 Recta Tangente y Normal

### Recta Tangente
La recta [tangente](../../..](../../../glossary.md)#tangente) a $y = f(x)$ en $(a, f(a))$:
$$y - f(a) = f'(a)(x - a)$$

### Recta Normal
La recta normal es perpendicular a la [tangente](../../..](../../../glossary.md)#tangente):
$$y - f(a) = -\frac{1}{f'(a)}(x - a) \quad (f'(a) \neq 0)$$

---

## 3.2 Razones de Cambio Relacionadas

### Concepto
Cuando varias cantidades varÃ­an con el tiempo y estÃ¡n relacionadas por una ecuaciÃ³n, sus tasas de cambio tambiÃ©n estÃ¡n relacionadas.

### Procedimiento
1. Dibujar un diagrama e identificar variables
2. Escribir la ecuaciÃ³n que relaciona las variables
3. Derivar implÃ­citamente respecto al tiempo $t$
4. Sustituir valores conocidos y resolver

---

## 3.3 Valores Extremos

### Definiciones
- **MÃ¡ximo absoluto:** $f(c) \geq f(x)$ para todo $x$ en el [dominio](../../..](../../../glossary.md)#dominio)
- **MÃ­nimo absoluto:** $f(c) \leq f(x)$ para todo $x$ en el [dominio](../../..](../../../glossary.md)#dominio)
- **MÃ¡ximo relativo:** $f(c) \geq f(x)$ para $x$ cerca de $c$
- **MÃ­nimo relativo:** $f(c) \leq f(x)$ para $x$ cerca de $c$

### Teorema de Weierstrass
Si $f$ es continua en $[a, b]$, entonces $f$ alcanza un mÃ¡ximo y un mÃ­nimo absolutos en $[a, b]$.

### Puntos CrÃ­ticos
$c$ es [punto crÃ­tico](../../..](../../../glossary.md)#punto-critico) si $f'(c) = 0$ o $f'(c)$ no existe.

### MÃ©todo del Intervalo Cerrado
Para encontrar extremos absolutos de $f$ continua en $[a, b]$:
1. Encontrar puntos crÃ­ticos en $(a, b)$
2. Evaluar $f$ en puntos crÃ­ticos y extremos $a$, $b$
3. El mayor valor es el mÃ¡ximo, el [menor](../../..](../../../glossary.md)#menor) es el mÃ­nimo

---

## 3.4 Criterio de la Primera Derivada

### Crecimiento y Decrecimiento
- $f'(x) > 0$ en $(a, b)$ â†’ $f$ es **creciente** en $(a, b)$
- $f'(x) < 0$ en $(a, b)$ â†’ $f$ es **decreciente** en $(a, b)$

### Prueba de Extremos
Si $c$ es [punto crÃ­tico](../../..](../../../glossary.md)#punto-critico):
- Si $f'$ cambia de $+$ a $-$ en $c$ â†’ **mÃ¡ximo relativo**
- Si $f'$ cambia de $-$ a $+$ en $c$ â†’ **mÃ­nimo relativo**
- Si $f'$ no cambia de signo â†’ **no es extremo**

---

## 3.5 Criterio de la Segunda Derivada

### Concavidad
- $f''(x) > 0$ â†’ **cÃ³ncava hacia arriba** (âˆª)
- $f''(x) < 0$ â†’ **cÃ³ncava hacia abajo** (âˆ©)

### Puntos de InflexiÃ³n
Un punto donde la [concavidad](../../..](../../../glossary.md)#concavidad) cambia de signo.
Candidatos: donde $f''(x) = 0$ o $f''(x)$ no existe.

### Prueba del Extremo
Si $f'(c) = 0$:
- $f''(c) > 0$ â†’ **mÃ­nimo relativo** en $c$
- $f''(c) < 0$ â†’ **mÃ¡ximo relativo** en $c$
- $f''(c) = 0$ â†’ prueba no concluyente

---

## 3.6 Problemas de OptimizaciÃ³n

### Procedimiento
1. **Entender:** Leer el problema, identificar quÃ© maximizar/minimizar
2. **Diagrama:** Dibujar y etiquetar variables
3. **Objetivo:** Escribir la [funciÃ³n](../../..](../../../glossary.md)#funcion) a optimizar
4. **RestricciÃ³n:** Usar la restricciÃ³n para eliminar variables
5. **Derivar:** Encontrar puntos crÃ­ticos
6. **Verificar:** Confirmar que es mÃ¡ximo o mÃ­nimo
7. **Responder:** Dar la respuesta en contexto

---

## 3.7 Aproximaciones y Diferenciales

### AproximaciÃ³n Lineal
$$f(x) \approx f(a) + f'(a)(x - a)$$

para $x$ cerca de $a$.

### Diferencial
$$dy = f'(x) \, dx$$

### PropagaciÃ³n de Errores
Si $y = f(x)$ y $\Delta x$ es el error en $x$:
$$\Delta y \approx f'(x) \Delta x$$

Error relativo: $\frac{\Delta y}{y} \approx \frac{f'(x)}{f(x)} \Delta x$

---

## 3.8 AnÃ¡lisis Completo de Funciones

### Pasos
1. **Dominio**
2. **Intersecciones:** con ejes $x$ e $y$
3. **SimetrÃ­a:** par, impar, periÃ³dica
4. **AsÃ­ntotas:** verticales, horizontales, oblicuas
5. **Intervalos de crecimiento/decrecimiento**
6. **MÃ¡ximos y mÃ­nimos relativos**
7. **[Concavidad](../../..](../../../glossary.md)#concavidad) y puntos de inflexiÃ³n**
8. **Graficar**

### AsÃ­ntota Oblicua
Si $\lim_{x \to \pm\infty} [f(x) - (mx + b)] = 0$, entonces $y = mx + b$ es [asÃ­ntota](../../..](../../../glossary.md)#asintota) oblicua.

---

## 3.9 MÃ©todo de Newton-Raphson

### FÃ³rmula
$$x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$$

### Procedimiento
1. Elegir $x_0$ (aproximaciÃ³n inicial)
2. Iterar hasta [convergencia](../../..](../../../glossary.md)#convergencia)
3. El [lÃ­mite](../../..](../../../glossary.md)#limite) es una raÃ­z de $f$

### Convergencia
- Funciona bien si $x_0$ estÃ¡ cerca de la raÃ­z
- Puede fallar si $f'(x_n) \approx 0$
